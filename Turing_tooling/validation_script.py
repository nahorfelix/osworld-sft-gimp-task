"""
Validation Script for OSWorld Task Deliveries.

Validates schema compliance, directory structure, and evaluation artefacts for a task delivery.
"""

import os
import json
import shutil
import argparse
from pathlib import Path

# Removed jsonschema import

def validate_json_structure(task_json_path):
    """
    Validate the structure and content of a task JSON file against the OSWorld schema.
    
    Performs comprehensive validation including required fields, data types, 
    enum values, and conditional constraints.
    
    Args:
        task_json_path (str): Path to the task JSON file to validate.
        
    Returns:
        tuple: (bool, dict or None) - (validation_passed, task_data_dict)
    """
    try:
        with open(task_json_path, 'r', encoding='utf-8') as f:
            task_data = json.load(f)
        
        errors = []
        
        # Required fields
        required_fields = [
            "id", "snapshot", "instruction", "source", "trajectory", "config", 
            "related_apps", "evaluator", "proxy", "fixed_ip", "possibility_of_env_change", 
            "model_pass_rate", "annotator_hints", "knowledge_points", "coverage"
        ]
        
        for field in required_fields:
            if field not in task_data:
                errors.append(f"Missing required field '{field}'")
        
        if errors:
            print(f"‚ùå JSON validation error: {', '.join(errors)}")
            return False, None
        
        # Validate types and values
        # id: string
        if not isinstance(task_data["id"], str):
            errors.append("'id' must be a string")
        
        # snapshot: enum
        valid_snapshots = [
            "chrome", "gimp", "libreoffice_calc", "libreoffice_impress", 
            "libreoffice_writer", "multi_apps", "os", "thunderbird", "vlc", "vs_code"
        ]
        if task_data["snapshot"] not in valid_snapshots:
            errors.append(f"'snapshot' must be one of {valid_snapshots}")
        
        # instruction, source, trajectory: strings
        for field in ["instruction", "source", "trajectory"]:
            if not isinstance(task_data[field], str):
                errors.append(f"'{field}' must be a string")
        
        # config: array of objects
        if not isinstance(task_data["config"], list):
            errors.append("'config' must be an array")
        else:
            valid_config_types = [
                "launch", "chrome_open_tabs", "chrome_close_tabs", "activate_window", 
                "execute", "update_browse_history", "download", "open", "sleep", 
                "command", "googledrive", "login"
            ]
            for i, item in enumerate(task_data["config"]):
                if not isinstance(item, dict) or "type" not in item or "parameters" not in item:
                    errors.append(f"'config' item {i} must have 'type' and 'parameters'")
                elif item["type"] not in valid_config_types:
                    errors.append(f"'config' item {i} type must be one of {valid_config_types}")
        
        # related_apps: array of strings from enum
        valid_related_apps = [
            "browser", "calc", "chrome", "excel", "gimp", "image", "libreoffice", 
            "libreoffice calc", "libreoffice_calc", "libreoffice_impress", 
            "libreoffice_writer", "os", "pdf", "picard", "powerpoint", "ppt", 
            "terminal", "thunderbird", "ubuntu_media_player", "vlc", "vs_code", 
            "vscode", "word", "writer"
        ]
        if not isinstance(task_data["related_apps"], list):
            errors.append("'related_apps' must be an array")
        else:
            for i, app in enumerate(task_data["related_apps"]):
                if not isinstance(app, str) or app not in valid_related_apps:
                    errors.append(f"'related_apps' item {i} must be one of {valid_related_apps}")
        
        # evaluator: object
        if not isinstance(task_data["evaluator"], dict):
            errors.append("'evaluator' must be an object")
        else:
            evaluator = task_data["evaluator"]
            
            # evaluator.postconfig: optional array of objects
            if "postconfig" in evaluator:
                if not isinstance(evaluator["postconfig"], list):
                    errors.append("'evaluator.postconfig' must be an array")
                else:
                    for i, item in enumerate(evaluator["postconfig"]):
                        if not isinstance(item, dict) or "type" not in item or "parameters" not in item:
                            errors.append(f"'evaluator.postconfig' item {i} must have 'type' and 'parameters'")
                        # type is string, parameters object
            
            # evaluator.func: required, string or array of strings from enum
            valid_funcs = [
                "check_accessibility_tree", "check_auto_saving_time", "check_brightness_decrease_and_structure_sim",
                "check_config_status", "check_contrast_increase_and_structure_sim", "check_csv", "check_direct_json_object",
                "check_enabled_experiments", "check_file_exists_and_structure_sim", "check_font_size", "check_global_key_play_pause",
                "check_gnome_favorite_apps", "check_green_background", "check_highlighted_words", "check_history_deleted",
                "check_image_file_size", "check_image_mirror", "check_image_size", "check_image_stretch_and_center",
                "check_include_exclude", "check_italic_font_size_14", "check_json", "check_json_keybindings", "check_json_settings",
                "check_left_panel", "check_line_number", "check_list", "check_moved_jpgs", "check_mp3_meta",
                "check_one_instance_when_started_from_file", "check_page_number_colors", "check_palette_and_structure_sim",
                "check_pdf_pages", "check_presenter_console_disable", "check_python_file_by_test_suite", "check_qt_bgcone",
                "check_qt_max_volume", "check_qt_minimal_view", "check_qt_slider_colours", "check_saturation_increase_and_structure_sim",
                "check_slide_orientation_Portrait", "check_structure_sim", "check_structure_sim_resized", "check_tabstops",
                "check_textbox_on_leftside", "check_thunderbird_filter", "check_thunderbird_folder", "check_thunderbird_prefs",
                "check_transition", "check_triangle_position", "compare_archive", "compare_audios", "compare_conference_city_in_order",
                "compare_config", "compare_csv", "compare_docx_files", "compare_docx_files_and_ignore_new_lines", "compare_docx_images",
                "compare_docx_lines", "compare_docx_tables", "compare_epub", "compare_font_names", "compare_htmls", "compare_image_list",
                "compare_image_text", "compare_images", "compare_line_spacing", "compare_numbered_lists", "compare_pdf_images",
                "compare_pdfs", "compare_pptx_files", "compare_python_pure_text", "compare_references", "compare_result_files",
                "compare_subscript_contains", "compare_table", "compare_text_file", "compare_time_in_speedtest_results",
                "compare_unique_train_records", "compare_videos", "compare_zip_files", "contains_page_break", "diff_text_file",
                "evaluate_colored_words_in_tables", "evaluate_presentation_fill_to_rgb_distance", "evaluate_strike_through_last_paragraph",
                "exact_match", "file_contains", "find_default_font", "fuzzy_place_math", "has_page_numbers_in_footers", "infeasible",
                "is_added_to_steam_cart", "is_cookie_deleted", "is_expected_active_tab", "is_expected_active_tab_approximate",
                "is_expected_bookmarks", "is_expected_installed_extensions", "is_expected_search_query", "is_expected_tabs",
                "is_expected_url_pattern_match", "is_extension_installed", "is_first_line_centered", "is_in_list", "is_in_vm_clickboard",
                "is_shortcut_on_desktop", "is_utc_0", "is_vlc_fullscreen", "is_vlc_playing", "is_vlc_recordings_folder", "literal_match",
                "match_in_list", "run_sqlite3"
            ]
            
            if "func" not in evaluator:
                errors.append("'evaluator' must have 'func'")
            else:
                func = evaluator["func"]
                if isinstance(func, str):
                    if func not in valid_funcs:
                        errors.append(f"'evaluator.func' must be a valid function name")
                elif isinstance(func, list):
                    for f in func:
                        if not isinstance(f, str) or f not in valid_funcs:
                            errors.append(f"'evaluator.func' items must be valid function names")
                else:
                    errors.append("'evaluator.func' must be string or array")
            
            # evaluator.conj: optional "or" or "and"
            if "conj" in evaluator:
                if evaluator["conj"] not in ["or", "and"]:
                    errors.append("'evaluator.conj' must be 'or' or 'and'")
            
            # evaluator.result: required, object or array of objects
            valid_result_types = [
                "accessibility_tree", "active_tab_html_parse", "active_tab_info", "active_tab_url_parse", 
                "active_url_from_accessTree", "audio_in_slide", "background_image_in_slide", "bookmarks", 
                "cache_file", "chrome_font_size", "cloud_file", "content_from_vm_file", "cookie_data", 
                "data_delete_automacally", "default_search_engine", "default_video_player", "enable_do_not_track", 
                "enable_enhanced_safety_browsing", "enabled_experiments", "find_installed_extension_name", 
                "find_unpacked_extension_path", "gimp_config_file", "googledrive_file", "history", 
                "list_directory", "new_startup_page", "open_tabs_info", "page_info", "profile_name", 
                "rule", "shortcuts_on_desktop", "url_dashPart", "url_path_parse", "vlc_config", 
                "vlc_playing_info", "vm_command_error", "vm_command_line", "vm_file", "vm_screen_size", 
                "vm_terminal_output", "vm_wallpaper", "vscode_config"
            ]
            
            if "result" not in evaluator:
                errors.append("'evaluator' must have 'result'")
            else:
                result = evaluator["result"]
                def validate_result_item(item, idx):
                    if not isinstance(item, dict):
                        errors.append(f"'evaluator.result' item {idx} must be an object")
                        return
                    if "type" not in item:
                        errors.append(f"'evaluator.result' item {idx} must have 'type'")
                    elif item["type"] not in valid_result_types:
                        errors.append(f"'evaluator.result' item {idx} 'type' must be valid")
                    # optional: path (string), dest (string), command (array of strings)
                    for opt in ["path", "dest"]:
                        if opt in item and not isinstance(item[opt], str):
                            errors.append(f"'evaluator.result' item {idx} '{opt}' must be string")
                    if "command" in item:
                        if not isinstance(item["command"], list) or not all(isinstance(c, str) for c in item["command"]):
                            errors.append(f"'evaluator.result' item {idx} 'command' must be array of strings")
                
                if isinstance(result, dict):
                    validate_result_item(result, 0)
                elif isinstance(result, list):
                    for i, item in enumerate(result):
                        validate_result_item(item, i)
                else:
                    errors.append("'evaluator.result' must be object or array")
            
            # evaluator.expected: required, object or array of objects
            valid_expected_types = [
                "cloud_file", "gotoRecreationPage_and_get_html_content", "info_from_website", "pdf_from_url", 
                "rule", "rule_relativeTime", "time_diff_range", "vm_command_line", "vm_file", "vm_window_size"
            ]
            
            if "expected" not in evaluator:
                errors.append("'evaluator' must have 'expected'")
            else:
                expected = evaluator["expected"]
                def validate_expected_item(item, idx):
                    if not isinstance(item, dict):
                        errors.append(f"'evaluator.expected' item {idx} must be an object")
                        return
                    if "type" not in item:
                        errors.append(f"'evaluator.expected' item {idx} must have 'type'")
                    elif item["type"] not in valid_expected_types:
                        errors.append(f"'evaluator.expected' item {idx} 'type' must be valid")
                    # optional: path (string), dest (string), rules (object)
                    for opt in ["path", "dest"]:
                        if opt in item and not isinstance(item[opt], str):
                            errors.append(f"'evaluator.expected' item {idx} '{opt}' must be string")
                    if "rules" in item and not isinstance(item["rules"], dict):
                        errors.append(f"'evaluator.expected' item {idx} 'rules' must be object")
                
                if isinstance(expected, dict):
                    validate_expected_item(expected, 0)
                elif isinstance(expected, list):
                    for i, item in enumerate(expected):
                        validate_expected_item(item, i)
                else:
                    errors.append("'evaluator.expected' must be object or array")
            
            # Check for extra fields in evaluator (additionalProperties: true, so allow)
        
        # Conditional: if related_apps contains browser or chrome, proxy should be true
        if any(app in task_data.get("related_apps", []) for app in ["browser", "chrome"]):
            if not task_data.get("proxy", False):
                errors.append("'proxy' must be true when related_apps contains 'browser' or 'chrome'")
        else:
            if task_data.get("proxy", False):
                errors.append("'proxy' must be false when related_apps does not contain 'browser' or 'chrome'")
        
        # proxy, fixed_ip: booleans
        for field in ["proxy", "fixed_ip"]:
            if not isinstance(task_data[field], bool):
                errors.append(f"'{field}' must be a boolean")
        
        # possibility_of_env_change: enum
        if task_data["possibility_of_env_change"] not in ["low", "medium", "high"]:
            errors.append("'possibility_of_env_change' must be 'low', 'medium', or 'high'")
        
        # model_pass_rate: object with number values 0-1
        if not isinstance(task_data["model_pass_rate"], dict):
            errors.append("'model_pass_rate' must be an object")
        else:
            for key, value in task_data["model_pass_rate"].items():
                if not isinstance(value, (int, float)) or not (0 <= value <= 1):
                    errors.append("'model_pass_rate' values must be numbers between 0 and 1")
        
        # annotator_hints, knowledge_points: string arrays
        for field in ["annotator_hints", "knowledge_points"]:
            if not isinstance(task_data[field], list):
                errors.append(f"'{field}' must be an array")
            else:
                for item in task_data[field]:
                    if not isinstance(item, str):
                        errors.append(f"'{field}' items must be strings")
        
        # coverage: string
        if not isinstance(task_data["coverage"], str):
            errors.append("'coverage' must be a string")
        
        # Check for extra fields (schema has additionalProperties: false)
        allowed_fields = {
            "id", "snapshot", "instruction", "source", "trajectory", "config", 
            "related_apps", "evaluator", "proxy", "fixed_ip", "possibility_of_env_change", 
            "model_pass_rate", "annotator_hints", "knowledge_points", "coverage"
        }
        extra_fields = set(task_data.keys()) - allowed_fields
        if extra_fields:
            errors.append(f"Extra fields not allowed: {', '.join(extra_fields)}")
        
        if errors:
            print(f"‚ùå JSON validation error: {', '.join(errors)}")
            return False, None
        
        print('‚úÖ JSON structure validation: PASSED')
        return True, task_data
    except json.JSONDecodeError as exc:
        print(f"‚ùå JSON validation error: Invalid JSON - {exc}")
        return False, None
    except Exception as exc:
        print(f"‚ùå Error loading JSON: {exc}")
        return False, None

def _parse_binary_score(raw_value: str, context: str) -> int:
    """
    Parse a binary score value (0 or 1) from a string.
    
    Args:
        raw_value (str): The raw string value to parse.
        context (str): Description of where this value comes from (for error messages).
        
    Returns:
        int: The parsed binary score (0 or 1).
        
    Raises:
        ValueError: If the value cannot be parsed as 0 or 1.
    """
    value_str = (raw_value or "").strip()
    if not value_str:
        raise ValueError(f"{context}: value is empty.")
    try:
        numeric = float(value_str)
    except ValueError as exc:
        raise ValueError(f"{context}: '{value_str}' is not numeric.") from exc
    if abs(numeric) < 1e-6:
        return 0
    if abs(numeric - 1) < 1e-6:
        return 1
    raise ValueError(f"{context}: {numeric} must be 0 or 1.")




def _extract_domain_candidates(task_data):
    """
    Extract domain candidates from task data.
    
    Looks for domain information in snapshot, related_apps, and other fields.
    
    Args:
        task_data (dict): The task data dictionary.
        
    Returns:
        list: List of unique domain candidate strings.
    """
    candidates = []
    if isinstance(task_data, dict):
        for key in ('snapshot', 'domain'):
            value = task_data.get(key)
            if isinstance(value, str):
                candidates.append(value)
        related = task_data.get('related_apps')
        if isinstance(related, list):
            candidates.extend(item for item in related if isinstance(item, str))
    seen = []
    for item in candidates:
        if item and item not in seen:
            seen.append(item)
    return seen


def _derive_domain_candidates(sft_dir: Path, task_data):
    """
    Derive domain candidates from SFT directory structure and task data.
    
    Combines domain information from task data with directory names in SFT folder.
    
    Args:
        sft_dir (Path): Path to the SFT directory.
        task_data (dict): The task data dictionary.
        
    Returns:
        list: List of unique domain candidate strings.
    """
    candidates = _extract_domain_candidates(task_data)
    seen = []
    for value in candidates:
        if value and value not in seen:
            seen.append(value)
    try:
        sft_path = Path(sft_dir)
        for child in sft_path.iterdir():
            if child.is_dir() and child.name not in ('Trajectory and Screenshot', 'Colab'):
                if child.name not in seen:
                    seen.append(child.name)
    except (FileNotFoundError, NotADirectoryError):
        pass
    return seen

def _locate_sft_score_file(sft_dir: Path, task_id: str, domain_candidates=None):
    """
    Locate the SFT score file within the SFT directory.
    
    Searches for score files based on task ID and domain candidates.
    
    Args:
        sft_dir (Path): Path to the SFT directory.
        task_id (str): The task ID to search for.
        domain_candidates (list, optional): List of domain candidates to search in.
        
    Returns:
        Path or None: Path to the score file if found, None otherwise.
    """
    sft_dir = Path(sft_dir)
    if not sft_dir.exists():
        return None

    # Prefer Trajectory and Screenshot as the primary location
    primary_candidates = [
        sft_dir / 'Trajectory and Screenshot' / 'evaluation_score.txt',
        sft_dir / 'Trajectory and Screenshot' / task_id / 'evaluation_score.txt',
    ]
    for candidate in primary_candidates:
        if candidate.exists():
            return candidate

    candidate_domains = []
    for domain in domain_candidates or []:
        if domain and domain not in candidate_domains:
            candidate_domains.append(domain)

    for domain in candidate_domains:
        candidate = sft_dir / domain / task_id / 'evaluation_score.txt'
        if candidate.exists():
            return candidate

    for subdir in sft_dir.iterdir():
        if subdir.is_dir() and subdir.name not in ('Trajectory and Screenshot', 'Colab'):
            candidate = subdir / task_id / 'evaluation_score.txt'
            if candidate.exists():
                return candidate

    matches = [p for p in sft_dir.rglob('evaluation_score.txt') if p.is_file()]
    if not matches:
        return None
    matches.sort(key=lambda p: len(p.parts))
    return matches[0]



def _ensure_expected_path(base_path, relative_parts, rearrange=False, search_patterns=None, must_be_dir=False, candidate_filter=None):
    """
    Ensure an expected path exists, with fallback search and rearrangement options.
    
    Validates path existence and provides flexible search capabilities.
    
    Args:
        base_path: Base directory path to search from.
        relative_parts: List of path components to join.
        rearrange (bool): Whether to allow path rearrangement during search.
        search_patterns (list, optional): Patterns to search for if expected path doesn't exist.
        must_be_dir (bool): Whether the found path must be a directory.
        candidate_filter (callable, optional): Filter function for candidate paths.
        
    Returns:
        Path or None: The found path, or None if not found.
    """
    base_path = Path(base_path)
    expected_path = base_path.joinpath(*relative_parts)
    if expected_path.exists():
        return expected_path
    patterns = search_patterns or [relative_parts[-1]]
    matches = []
    for pattern in patterns:
        for candidate in base_path.rglob(pattern):
            if candidate == expected_path:
                return expected_path
            if must_be_dir and not candidate.is_dir():
                continue
            if not must_be_dir and candidate.is_dir():
                continue
            if candidate_filter and not candidate_filter(candidate):
                continue
            matches.append(candidate)
    if not matches:
        return None
    matches = sorted(matches, key=lambda p: len(p.parts))
    selected = matches[0]
    if not rearrange:
        kind = 'directory' if must_be_dir else 'file'
        print(f"‚ùå Structure check: Expected {kind} {expected_path} missing (found at {selected}). Use --rearrange to repair.")
        return None
    target_parent = expected_path.parent
    target_parent.mkdir(parents=True, exist_ok=True)
    try:
        shutil.move(str(selected), str(expected_path))
        print(f"üîÅ Structure check: Moved {selected} to {expected_path}.")
        return expected_path
    except Exception as exc:
        print(f"‚ùå Structure check: Failed to move {selected} to {expected_path}: {exc}")
        return None

def _normalize_run_name(name):
    """
    Normalize run directory names to run_X format (no leading zeros).
    
    Converts various run name formats to standardized run_X format.
    
    Args:
        name (str): The run name to normalize.
        
    Returns:
        str: Normalized run name in run_X format.
    """
    import re
    # Extract number from various formats: run_1, run_01, Run_1, Run_01, etc.
    match = re.match(r'(?i)^run_?(\d+)$', name.strip())
    if match:
        num = int(match.group(1))  # This removes leading zeros
        return f'run_{num}'
    return name

def _normalize_annotator_name(name):
    """
    Normalize annotator directory names to annotator_X format (no leading zeros).
    
    Converts various annotator name formats to standardized annotator_X format.
    
    Args:
        name (str): The annotator name to normalize.
        
    Returns:
        str: Normalized annotator name in annotator_X format.
    """
    import re
    # Extract number from various formats: annotator1, annotator_1, Annotator1, etc.
    match = re.match(r'(?i)^annotator_?(\d+)$', name.strip())
    if match:
        num = int(match.group(1))  # This removes leading zeros
        return f'annotator_{num}'
    return name

def _normalize_directory_names(base_path, rearrange=False):
    """
    Normalize directory names in the given path.
    
    Renames directories to standardized formats when rearrange is enabled.
    
    Args:
        base_path: Base directory path to normalize.
        rearrange (bool): Whether to perform directory renaming.
    """
    if not rearrange:
        return
    
    base_path = Path(base_path)
    if not base_path.exists():
        return
    
    # Normalize run directories in claude folder
    claude_dir = _locate_claude_folder(base_path)
    if claude_dir:
        # First, collect all directories and their normalized names
        dirs_to_process = []
        for child in claude_dir.iterdir():
            if child.is_dir():
                normalized_name = _normalize_run_name(child.name)
                dirs_to_process.append((child, normalized_name))
        
        # Process directories, handling conflicts
        for child, normalized_name in dirs_to_process:
            if normalized_name != child.name:
                target_path = claude_dir / normalized_name
                if not target_path.exists():
                    try:
                        shutil.move(str(child), str(target_path))
                        print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name}")
                    except Exception as exc:
                        print(f"‚ùå Name normalization: Failed to rename {child.name}: {exc}")
                else:
                    # Target exists - check if it's the same directory (case-insensitive filesystem)
                    try:
                        # Check if they're the same directory by comparing inodes
                        child_stat = child.stat()
                        target_stat = target_path.stat()
                        if child_stat.st_ino == target_stat.st_ino:
                            # Same directory - try to rename to normalize the name
                            try:
                                # Create a temporary name to avoid conflict
                                temp_name = f"{normalized_name}_temp_{child_stat.st_ino}"
                                temp_path = child.parent / temp_name
                                shutil.move(str(child), str(temp_path))
                                shutil.move(str(temp_path), str(target_path))
                                print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name} (case-insensitive filesystem)")
                            except Exception as exc:
                                print(f"‚ÑπÔ∏è Name normalization: {child.name} and {normalized_name} are the same directory (case-insensitive filesystem)")
                        else:
                            # Different directories - merge contents or report conflict
                            print(f"‚ö†Ô∏è Name normalization: Cannot rename {child.name} to {normalized_name} (target exists)")
                            print(f"   Consider manually merging contents from {child} into {target_path}")
                    except (OSError, FileNotFoundError):
                        # Fallback to path comparison
                        if child.resolve() == target_path.resolve():
                            try:
                                # Create a temporary name to avoid conflict
                                temp_name = f"{normalized_name}_temp"
                                temp_path = child.parent / temp_name
                                shutil.move(str(child), str(temp_path))
                                shutil.move(str(temp_path), str(target_path))
                                print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name} (case-insensitive filesystem)")
                            except Exception as exc:
                                print(f"‚ÑπÔ∏è Name normalization: {child.name} and {normalized_name} are the same directory (case-insensitive filesystem)")
                        else:
                            print(f"‚ö†Ô∏è Name normalization: Cannot rename {child.name} to {normalized_name} (target exists)")
                            print(f"   Consider manually merging contents from {child} into {target_path}")
    
    # Normalize annotator directories
    annot_root = _locate_annotator_root(base_path)
    if annot_root:
        # First, collect all directories and their normalized names
        dirs_to_process = []
        for child in annot_root.iterdir():
            if child.is_dir():
                normalized_name = _normalize_annotator_name(child.name)
                dirs_to_process.append((child, normalized_name))
        
        # Process directories, handling conflicts
        for child, normalized_name in dirs_to_process:
            if normalized_name != child.name:
                target_path = annot_root / normalized_name
                if not target_path.exists():
                    try:
                        shutil.move(str(child), str(target_path))
                        print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name}")
                    except Exception as exc:
                        print(f"‚ùå Name normalization: Failed to rename {child.name}: {exc}")
                else:
                    # Target exists - check if it's the same directory (case-insensitive filesystem)
                    try:
                        # Check if they're the same directory by comparing inodes
                        child_stat = child.stat()
                        target_stat = target_path.stat()
                        if child_stat.st_ino == target_stat.st_ino:
                            # Same directory - try to rename to normalize the name
                            try:
                                # Create a temporary name to avoid conflict
                                temp_name = f"{normalized_name}_temp_{child_stat.st_ino}"
                                temp_path = child.parent / temp_name
                                shutil.move(str(child), str(temp_path))
                                shutil.move(str(temp_path), str(target_path))
                                print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name} (case-insensitive filesystem)")
                            except Exception as exc:
                                print(f"‚ÑπÔ∏è Name normalization: {child.name} and {normalized_name} are the same directory (case-insensitive filesystem)")
                        else:
                            # Different directories - merge contents or report conflict
                            print(f"‚ö†Ô∏è Name normalization: Cannot rename {child.name} to {normalized_name} (target exists)")
                            print(f"   Consider manually merging contents from {child} into {target_path}")
                    except (OSError, FileNotFoundError):
                        # Fallback to path comparison
                        if child.resolve() == target_path.resolve():
                            try:
                                # Create a temporary name to avoid conflict
                                temp_name = f"{normalized_name}_temp"
                                temp_path = child.parent / temp_name
                                shutil.move(str(child), str(temp_path))
                                shutil.move(str(temp_path), str(target_path))
                                print(f"üîÅ Name normalization: Renamed {child.name} to {normalized_name} (case-insensitive filesystem)")
                            except Exception as exc:
                                print(f"‚ÑπÔ∏è Name normalization: {child.name} and {normalized_name} are the same directory (case-insensitive filesystem)")
                        else:
                            print(f"‚ö†Ô∏è Name normalization: Cannot rename {child.name} to {normalized_name} (target exists)")
                            print(f"   Consider manually merging contents from {child} into {target_path}")

def _has_run_dirs(path):
    """
    Check if a directory contains any run directories.
    
    Looks for directories starting with 'run_' (case-insensitive).
    
    Args:
        path: Path to check for run directories.
        
    Returns:
        bool: True if run directories are found, False otherwise.
    """
    try:
        return any(child.is_dir() and child.name.lower().startswith('run_') for child in Path(path).iterdir())
    except (FileNotFoundError, PermissionError):
        return False

def _validate_trajectory_assets(folder, description):
    """
    Validate trajectory assets in a folder.
    
    Checks for required PNG screenshots and XML files in trajectory folders.
    
    Args:
        folder: Path to the trajectory folder to validate.
        description (str): Description of the folder for error messages.
        
    Returns:
        bool: True if validation passes, False otherwise.
    """
    if folder is None:
        return False
    folder = Path(folder)
    if not folder.exists():
        print(f"‚ùå Structure check: {description} not found.")
        return False
    png_files = list(folder.glob('*.png'))
    xml_files = list(folder.glob('*.xml'))
    if not png_files:
        print(f"‚ùå Structure check: {description} has no PNG screenshots.")
        return False
    if not xml_files:
        print(f"‚ùå Structure check: {description} has no XML accessibility trees.")
        return False
    if len(png_files) != len(xml_files):
        print(f"‚ùå Structure check: {description} has {len(png_files)} PNG files and {len(xml_files)} XML files; counts must match.")
        return False
    return True


def _prepare_trajectory_folder(folder, description, rearrange, expected_child=None):
    """
    Prepare trajectory folder by organizing assets.
    
    Moves trajectory assets from subdirectories to the main folder if needed.
    
    Args:
        folder: Path to the trajectory folder.
        description (str): Description for logging.
        rearrange (bool): Whether to rearrange files.
        expected_child (str, optional): Expected child directory name.
        
    Returns:
        bool: True if preparation succeeds, False otherwise.
    """
    folder = Path(folder)
    png_files = list(folder.glob('*.png'))
    xml_files = list(folder.glob('*.xml'))
    if png_files or xml_files:
        return True

    subdirs = [child for child in folder.iterdir() if child.is_dir() and child.name != 'Colab']
    target_dir = None
    if expected_child:
        for child in subdirs:
            if child.name == expected_child:
                target_dir = child
                break
    if target_dir is None and len(subdirs) == 1:
        target_dir = subdirs[0]

    if target_dir is None:
        if not subdirs:
            print(f"‚ùå Structure check: {description} has no trajectory assets.")
        else:
            print(f"‚ùå Structure check: {description} files are nested in unexpected subdirectories: {[d.name for d in subdirs]}.")
        return False

    if not rearrange:
        print(f"‚ùå Structure check: {description} assets are nested in {target_dir.name}; use --rearrange to normalize.")
        return False

    moved_any = False
    for item in target_dir.iterdir():
        destination = folder / item.name
        if destination.exists():
            try:
                if destination.is_dir():
                    shutil.rmtree(destination)
                else:
                    destination.unlink()
            except Exception as exc:
                print(f"‚ùå Structure check: Failed to replace {destination}: {exc}")
                return False
        shutil.move(str(item), str(destination))
        moved_any = True

    if moved_any:
        print(f"üîÅ Structure check: Flattened contents from {target_dir} into {folder}.")

    try:
        target_dir.rmdir()
    except OSError:
        pass

    return True


def _locate_claude_folder(task_folder, phase=1):
    """
    Locate the Claude model folder based on phase.
    
    Finds the appropriate Claude folder name for the given phase.
    
    Args:
        task_folder: Base task folder to search in.
        phase (int): Phase number (1 or 2) to determine folder name.
        
    Returns:
        Path or None: Path to the Claude folder if found, None otherwise.
    """
    base = Path(task_folder)

    folder_name = 'claude-4-sonnet-20250514' if phase == 1 else 'claude-sonnet-4-5-20250929'
    expected = base / folder_name
    if expected.exists():
        return expected
    candidates = [child for child in base.iterdir() if child.is_dir() and child.name.startswith('claude-4-sonnet' if phase == 1 else 'claude-sonnet') and _has_run_dirs(child)]
    if candidates:
        return sorted(candidates, key=lambda p: len(p.parts))[0]
    search_patterns = [
        folder_name,
        folder_name + '*',
        '*' + folder_name + '*',
    ]
    for pattern in search_patterns:
        matches = [candidate for candidate in base.rglob(pattern) if candidate.is_dir() and _has_run_dirs(candidate)]
        if matches:
            return sorted(matches, key=lambda p: len(p.parts))[0]
    return None

def _locate_annotator_root(task_folder):
    """
    Locate the annotator trajectory root folder.
    
    Searches for the annotator trajectory directory with various naming conventions.
    
    Args:
        task_folder: Base task folder to search in.
        
    Returns:
        Path or None: Path to the annotator root folder if found, None otherwise.
    """
    base = Path(task_folder)
    for name in ('Annotator Trajectory', 'Annotator_trajectory', 'Annotator trajectory'):
        candidate = base / name
        if candidate.exists():
            return candidate
    matches = []
    for pattern in ('Annotator Trajectory', 'Annotator_trajectory', 'Annotator trajectory'):
        matches.extend(candidate for candidate in base.rglob(pattern) if candidate.is_dir())
    if matches:
        return sorted(matches, key=lambda p: len(p.parts))[0]
    return None

def validate_pass_k(task_folder, task_id, rearrange=False, phase=1):
    """
    Validate pass@k metric for Claude model runs.
    
    Checks that the required number of successful runs exist for the given phase.
    
    Args:
        task_folder: Base task folder to validate.
        task_id (str): Task identifier.
        rearrange (bool): Whether to rearrange directories.
        phase (int): Phase number (1 or 2) determining expected run count.
        
    Returns:
        bool: True if validation passes, False otherwise.
    """
    expected_runs = 16 if phase == 1 else 8
    folder_name = 'claude-4-sonnet-20250514' if phase == 1 else 'claude-sonnet-4-5-20250929'
    claude_dir = _locate_claude_folder(task_folder, phase)
    if not claude_dir:
        print(f'‚ùå Pass@{expected_runs} validation: {folder_name} folder not found.')
        return False

    results = []
    for i in range(1, expected_runs + 1):
        run_dir = None
        for name in (f"run_{i:02d}", f"run_{i}"):
            candidate = Path(claude_dir) / name
            if candidate.exists():
                run_dir = candidate
                break
        if run_dir is None:
            expected_path = Path(claude_dir) / f"run_{i:02d}"
            print(f"‚ùå Pass@{expected_runs} validation: Run folder {expected_path} not found.")
            return False

        traj_dir = run_dir / 'Trajectory and Screenshot'
        if not traj_dir.exists():
            print(f"‚ùå Pass@{expected_runs} validation: 'Trajectory and Screenshot' missing in {run_dir}.")
            return False

        expected_file = traj_dir / 'result.txt'
        located_file = None
        if expected_file.exists():
            located_file = expected_file
        else:
            nested_candidate = traj_dir / task_id / 'result.txt'
            if nested_candidate.exists():
                located_file = nested_candidate
            else:
                matches = [p for p in traj_dir.rglob('result.txt') if p.is_file()]
                if not matches:
                    print(f"‚ùå Pass@{expected_runs} validation: result.txt not found under {traj_dir}.")
                    return False
                if len(matches) > 1:
                    relative_matches = [str(match.relative_to(run_dir)) for match in matches]
                    print(f"‚ùå Pass@{expected_runs} validation: Multiple result.txt files found in {traj_dir}: {relative_matches}")
                    return False
                located_file = matches[0]

        if located_file != expected_file:
            if not rearrange:
                print(f"‚ùå Pass@{expected_runs} validation: result.txt located at {located_file} instead of {expected_file}. Use --rearrange to repair.")
                return False
            try:
                expected_file.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(located_file), str(expected_file))
                print(f'üîÅ Pass@{expected_runs} validation: Moved {located_file} to {expected_file}.')
                nested_parent = expected_file.parent / task_id
                if nested_parent.exists() and nested_parent.is_dir():
                    try:
                        nested_parent.rmdir()
                    except OSError:
                        pass
            except Exception as exc:
                print(f"‚ùå Pass@{expected_runs} validation: Failed to move {located_file} to {expected_file}: {exc}")
                return False

        raw_value = expected_file.read_text(encoding='utf-8')
        try:
            val = _parse_binary_score(raw_value, f"Pass@{expected_runs} result in {expected_file}")
        except ValueError as exc:
            print(f"‚ùå Pass@{expected_runs} validation: {exc}")
            return False
        results.append(val)

    num_runs = len(results)
    print(f'üìä Pass@{expected_runs} validation: Found {num_runs} runs.')
    if num_runs != expected_runs:
        print(f'‚ùå Pass@{expected_runs} validation: Not exactly {expected_runs} runs.')
        return False

    avg = sum(results) / num_runs if num_runs else 0
    if avg == 1:
        print(f'‚ùå Pass@{expected_runs} validation: Average is {avg}, which is invalid (must be less than 1, 0 is acceptable).')
        return False

    print(f'‚úÖ Pass@{expected_runs} validation: PASSED with average {avg:.2f}')
    return True


def check_file_structure(task_folder, task_id, rearrange=False, task_data=None, phase=1):
    """
    Check the overall file structure of a task delivery.
    
    Validates directory layout, required files, and folder organization.
    
    Args:
        task_folder: Base task folder to check.
        task_id (str): Task identifier.
        rearrange (bool): Whether to rearrange directories.
        task_data (dict, optional): Task data for validation.
        phase (int): Phase number for validation rules.
        
    Returns:
        bool: True if structure is valid, False otherwise.
    """
    base = Path(task_folder)
    all_good = True
    folder_name = 'claude-4-sonnet-20250514' if phase == 1 else 'claude-sonnet-4-5-20250929'
    expected_runs = 16 if phase == 1 else 8
    
    # Normalize directory names if rearrange is enabled
    if rearrange:
        _normalize_directory_names(base, rearrange)
    json_path = _ensure_expected_path(base, [f'{task_id}.json'], rearrange, search_patterns=[f'{task_id}.json'])
    if json_path is None or not json_path.exists():
        print(f'‚ùå Structure check: Required JSON {task_id}.json missing.')
        all_good = False
    sft_dir = _ensure_expected_path(base, ['SFT'], rearrange, search_patterns=['SFT'], must_be_dir=True)
    if not sft_dir:
        print('‚ùå Structure check: SFT/ directory missing.')
        all_good = False
    else:
        domain_candidates = _derive_domain_candidates(sft_dir, task_data)
        colab_dir = _ensure_expected_path(sft_dir, ['Colab'], rearrange, search_patterns=['Colab'], must_be_dir=True)
        if not colab_dir:
            if rearrange:
                colab_dir = sft_dir / 'Colab'
                colab_dir.mkdir(parents=True, exist_ok=True)
                print(f"üîÅ Structure check: Created {colab_dir}.")
            else:
                print('‚ùå Structure check: SFT/Colab directory missing.')
                all_good = False
        if colab_dir:
            colab_dir = Path(colab_dir)
            notebook_groups = {}
            for nb_path in sft_dir.rglob('*.ipynb'):
                if not nb_path.is_file():
                    continue
                if colab_dir in nb_path.parents or nb_path.parent == colab_dir:
                    continue
                try:
                    relative_parent = nb_path.parent.relative_to(sft_dir)
                    context_label = relative_parent.as_posix() or '.'
                except ValueError:
                    context_label = nb_path.parent.name
                notebook_groups.setdefault(context_label, []).append(nb_path)

            def _relocate_notebook_group(paths, context_label):
                nonlocal all_good
                if not paths:
                    return
                label = f"SFT/{context_label}" if context_label != '.' else 'SFT'
                if not rearrange:
                    print(f"\u274c Structure check: {label} contains notebook files outside SFT/Colab/. Use --rearrange to relocate them.")
                    all_good = False
                    return
                moved_any = False
                for nb_path in paths:
                    target = colab_dir / nb_path.name
                    try:
                        if target.exists():
                            if target.is_dir():
                                shutil.rmtree(target)
                            else:
                                target.unlink()
                        shutil.move(str(nb_path), str(target))
                        moved_any = True
                    except Exception as exc:
                        print(f"\u274c Structure check: Failed to move {nb_path} to {target}: {exc}")
                        all_good = False
                        moved_any = False
                        break
                if moved_any:
                    print(f"\U0001f501 Structure check: Moved notebook files from {label} into SFT/Colab/.")
                    for nb_path in paths:
                        parent = nb_path.parent
                        while parent not in (colab_dir, sft_dir) and parent.exists() and not any(parent.iterdir()):
                            try:
                                parent.rmdir()
                            except OSError:
                                break
                            parent = parent.parent

            for context_label, paths in notebook_groups.items():
                _relocate_notebook_group(paths, context_label)
        traj_dir = _ensure_expected_path(
            sft_dir,
            ['Trajectory and Screenshot'],
            rearrange,
            search_patterns=['Trajectory and Screenshot', 'Trajectory_and_Screenshot'],
            must_be_dir=True,
        )
        if not traj_dir:
            all_good = False
        else:
            if not _prepare_trajectory_folder(traj_dir, 'SFT/Trajectory and Screenshot', rearrange, expected_child=task_id):
                all_good = False
            elif not _validate_trajectory_assets(traj_dir, 'SFT/Trajectory and Screenshot'):
                all_good = False
        score_path = _locate_sft_score_file(sft_dir, task_id, domain_candidates)
        score_path_obj = Path(score_path) if score_path else None
        if score_path_obj is None or not score_path_obj.exists():
            print('\u274c Structure check: SFT evaluation_score.txt missing.')
            all_good = False
        elif rearrange and traj_dir:
            # Expected location is SFT/Trajectory and Screenshot/evaluation_score.txt
            expected_score = traj_dir / 'evaluation_score.txt'
            
            # Only move if the file is not already in the expected location
            if score_path_obj != expected_score:
                try:
                    expected_score.parent.mkdir(parents=True, exist_ok=True)
                    # Remove target if it exists
                    if expected_score.exists():
                        expected_score.unlink()
                    shutil.move(str(score_path_obj), str(expected_score))
                    print(f'\U0001f501 Structure check: Moved {score_path_obj} to {expected_score}.')
                    score_path_obj = expected_score
                except Exception as exc:
                    print(f'\u274c Structure check: Failed to move {score_path_obj} to {expected_score}: {exc}')
                    all_good = False
    claude_dir = _ensure_expected_path(
        base,
        [folder_name],
        rearrange,
        search_patterns=[folder_name, folder_name + '*', '*' + folder_name + '*'],
        must_be_dir=True,
        candidate_filter=_has_run_dirs,
    )
    if not claude_dir:
        print(f'‚ùå Structure check: {folder_name}/ directory missing.')
        all_good = False
    else:
        for i in range(1, expected_runs + 1):
            expected_run = f'run_{i:02d}'
            run_dir = None
            for candidate_name in (expected_run, f'run_{i}'):
                candidate = Path(claude_dir) / candidate_name
                if candidate.exists():
                    run_dir = candidate
                    break
            if run_dir is None:
                run_dir = _ensure_expected_path(
                    claude_dir,
                    [expected_run],
                    rearrange,
                    search_patterns=[expected_run, f'run_{i}'],
                    must_be_dir=True,
                )
            if not run_dir:
                print(f'‚ùå Structure check: Missing Claude run folder {expected_run}.')
                all_good = False
                continue
            traj_dir = _ensure_expected_path(
                run_dir,
                ['Trajectory and Screenshot'],
                rearrange,
                search_patterns=['Trajectory and Screenshot', 'Trajectory_and_Screenshot'],
                must_be_dir=True,
            )
            if not traj_dir:
                print(f'‚ùå Structure check: Missing Trajectory and Screenshot for {Path(run_dir).name}.')
                all_good = False
                continue
            if not _prepare_trajectory_folder(
                traj_dir,
                f"{Path(claude_dir).name}/{Path(run_dir).name}/Trajectory and Screenshot",
                rearrange,
                expected_child=task_id,
            ):
                all_good = False
                continue
            if not _validate_trajectory_assets(traj_dir, f"{Path(claude_dir).name}/{Path(run_dir).name}/Trajectory and Screenshot"):
                all_good = False
    annot_root = _ensure_expected_path(
        base,
        ['Annotator Trajectory'],
        rearrange,
        search_patterns=['Annotator Trajectory', 'Annotator_trajectory', 'Annotator trajectory'],
        must_be_dir=True,
    )
    if not annot_root:
        print('‚ùå Structure check: Annotator Trajectory/ directory missing.')
        all_good = False
    else:
        for idx in range(1, 4):
            canonical = f'annotator{idx}'
            annot_dir = None
            for variant in (canonical, f'annotator_{idx}', f'annotaor_{idx}', f'annotaor{idx}', f'annotator{idx:02d}'):
                candidate = Path(annot_root) / variant
                if candidate.exists():
                    annot_dir = candidate
                    break
            if annot_dir is None:
                annot_dir = _ensure_expected_path(
                    annot_root,
                    [canonical],
                    rearrange,
                    search_patterns=[canonical, f'annotator_{idx}', f'annotaor_{idx}', f'annotaor{idx}', f'annotator{idx:02d}'],
                    must_be_dir=True,
                )
            if not annot_dir:
                print(f'‚ùå Structure check: Missing annotator folder for annotator {idx}.')
                all_good = False
                continue
            colab_dir = _ensure_expected_path(
                annot_dir,
                ['Colab'],
                rearrange,
                search_patterns=['Colab'],
                must_be_dir=True,
            )
            if not colab_dir:
                print(f"‚ùå Structure check: {Path(annot_root).name}/{Path(annot_dir).name} missing Colab/ directory.")
                all_good = False

            eval_file = _ensure_expected_path(
                annot_dir,
                ['evaluation_score.txt'],
                rearrange,
                search_patterns=['evaluation_score.txt'],
            )
            if eval_file is None or not eval_file.exists():
                print(f'‚ùå Structure check: evaluation_score.txt missing for annotator {idx}.')
                all_good = False
            traj_dir = _ensure_expected_path(
                annot_dir,
                ['Trajectory and Screenshot'],
                rearrange,
                search_patterns=['Trajectory and Screenshot', 'Trajectory_and_Screenshot'],
                must_be_dir=True,
            )
            if not traj_dir:
                print(f'‚ùå Structure check: Trajectory and Screenshot missing for annotator {idx}.')
                all_good = False
                continue
            if not _prepare_trajectory_folder(
                traj_dir,
                f"{Path(annot_root).name}/{Path(annot_dir).name}/Trajectory and Screenshot",
                rearrange,
                expected_child=task_id,
            ):
                all_good = False
                continue
            if not _validate_trajectory_assets(
                traj_dir,
                f"{Path(annot_root).name}/{Path(annot_dir).name}/Trajectory and Screenshot",
            ):
                all_good = False
    if all_good:
        print('‚úÖ File structure check: PASSED')
    return all_good

def check_sft_eval_score(task_folder, task_id, task_data=None):
    """
    Check SFT evaluation score file.
    
    Validates the presence and content of the SFT evaluation score file.
    
    Args:
        task_folder: Base task folder containing SFT directory.
        task_id (str): Task identifier.
        task_data (dict, optional): Task data for domain derivation.
        
    Returns:
        bool: True if score file is valid, False otherwise.
    """
    sft_dir = Path(task_folder) / 'SFT'
    domain_candidates = _derive_domain_candidates(sft_dir, task_data)
    score_path = _locate_sft_score_file(sft_dir, task_id, domain_candidates)
    score_path_obj = Path(score_path) if score_path else None
    if score_path_obj is None or not score_path_obj.exists():
        print('‚ùå SFT eval score check: evaluation_score.txt not found in SFT.')
        return False

    raw_value = score_path_obj.read_text(encoding='utf-8')
    try:
        val = _parse_binary_score(raw_value, f"SFT eval score ({score_path_obj})")
    except ValueError as exc:
        print(f'‚ùå SFT eval score check: {exc}')
        return False

    if val != 1:
        print(f'‚ùå SFT eval score check: Score is {val}, not 1.')
        return False
    print('‚úÖ SFT eval score check: PASSED')
    return True


def check_annotator_scores(task_folder):
    """
    Check annotator trajectory scores.
    
    Validates the presence and content of annotator score files.
    
    Args:
        task_folder: Base task folder containing annotator trajectories.
        
    Returns:
        bool: True if annotator scores are valid, False otherwise.
    """
    annot_root = _locate_annotator_root(task_folder)
    if not annot_root:
        print('‚ùå Annotator scores check: Annotator Trajectory directory not found.')
        return False

    scores = []
    for idx in range(1, 4):
        annot_dir = None
        for variant in (f'annotator{idx}', f'annotator_{idx}', f'annotaor_{idx}', f'annotaor{idx}', f'annotator{idx:02d}'):
            candidate = Path(annot_root) / variant
            if candidate.exists():
                annot_dir = candidate
                break
        if annot_dir is None:
            print(f'‚ùå Annotator scores check: Annotator folder for annotator {idx} not found.')
            return False

        score_file = annot_dir / 'evaluation_score.txt'
        if not score_file.exists():
            print(f'‚ùå Annotator scores check: evaluation_score.txt not found for annotator {idx}.')
            return False

        raw_value = score_file.read_text(encoding='utf-8')
        try:
            val = _parse_binary_score(raw_value, f"Annotator {idx} score ({score_file})")
        except ValueError as exc:
            print(f'‚ùå Annotator scores check: {exc}')
            return False
        scores.append(val)

    count_1 = scores.count(1)
    count_0 = scores.count(0)
    print(f'üìä Annotator scores check: {count_1} passed (1), {count_0} failed (0).')
    if 1 not in scores or 0 not in scores:
        print('‚ùå Annotator scores check: Scores do not include both 1 and 0.')
        return False
    print('‚úÖ Annotator scores check: PASSED')
    return True


def check_notebook_assistant_cells(task_folder):
    """
    Check notebook assistant cells for proper content.
    
    Validates that notebook cells contain appropriate assistant-generated content.
    
    Args:
        task_folder: Base task folder to search for notebooks.
        
    Returns:
        bool: True if notebook validation passes, False otherwise.
    """
    task_path = Path(task_folder)
    notebooks = list(task_path.rglob('*.ipynb'))
    if not notebooks:
        print('‚ÑπÔ∏è Notebook assistant check: No notebooks found.')
        return True

    all_good = True
    for notebook in notebooks:
        try:
            data = json.loads(notebook.read_text(encoding='utf-8'))
        except Exception as exc:
            print(f"‚ùå Notebook assistant check: Failed to read {notebook}: {exc}")
            all_good = False
            continue

        cells = data.get('cells', [])
        for idx, cell in enumerate(cells):
            source = cell.get('source', [])
            if isinstance(source, list):
                text = ''.join(source)
            elif isinstance(source, str):
                text = source
            else:
                text = ''
            stripped = text.lstrip()
            if stripped.startswith('**[assistant]') and 'Executing step' in text:
                rel_path = notebook.relative_to(task_path)
                print(f"‚ùå Notebook assistant check: Disallowed 'Executing step' in cell {idx} of {rel_path}.")
                all_good = False

    if all_good:
        print('‚úÖ Notebook assistant check: PASSED')
    return all_good


def check_no_args_json(task_folder):
    """
    Check that no args.json files are present in the task folder.
    
    Ensures that sensitive configuration files are not included in deliveries.
    
    Args:
        task_folder: Base task folder to check.
        
    Returns:
        bool: True if no args.json files found, False otherwise.
    """
    for root, _dirs, files in os.walk(task_folder):
        if 'args.json' in files:
            print(f'‚ùå No args.json check: args.json found in {root}')
            return False
    print('‚úÖ No args.json check: PASSED')
    return True

def main(delivery_folder, task_id, selected_checks, rearrange, phase=1):
    """
    Main validation function for OSWorld task deliveries.
    
    Orchestrates all validation checks for a task delivery folder.
    
    Args:
        delivery_folder: Root delivery folder path.
        task_id (str): Task identifier to validate.
        selected_checks (list): List of validation checks to perform.
        rearrange (bool): Whether to rearrange directory structure.
        phase (int): Phase number (1 or 2) for validation rules.
    """
    task_folder = Path(delivery_folder) / task_id
    if not task_folder.exists():
        print(f'‚ùå Task folder {task_folder} not found.')
        return
    task_json_path = task_folder / f'{task_id}.json'
    if not task_json_path.exists():
        print(f'‚ùå Task JSON {task_json_path} not found.')
        return
    valid, task_data = validate_json_structure(task_json_path) if 'json' in selected_checks else (True, None)
    if not valid and 'json' in selected_checks:
        return
    if any(check in selected_checks for check in ['passk', 'structure', 'sft_score', 'annotator_scores', 'no_args']):
        if task_data is None:
            try:
                task_data = json.loads(task_json_path.read_text(encoding='utf-8'))
            except Exception as exc:
                print(f'‚ùå Error loading task JSON: {exc}')
                return
    if rearrange and 'structure' not in selected_checks:
        if task_data is None:
            try:
                task_data = json.loads(task_json_path.read_text(encoding='utf-8'))
            except Exception as exc:
                print(f'‚ùå Error loading task JSON: {exc}')
                return
        # Normalize directory names first
        _normalize_directory_names(task_folder, rearrange)
        check_file_structure(task_folder, task_id, rearrange, task_data, phase)
    check_entries = [
        ('structure', lambda: check_file_structure(task_folder, task_id, rearrange, task_data, phase)),
        ('passk', lambda: validate_pass_k(task_folder, task_id, rearrange, phase)),
        ('sft_score', lambda: check_sft_eval_score(task_folder, task_id, task_data)),
        ('annotator_scores', lambda: check_annotator_scores(task_folder)),
        ('no_args', lambda: check_no_args_json(task_folder)),
    ]
    if phase == 1:
        check_entries.append(('notebook_assistant', lambda: check_notebook_assistant_cells(task_folder)))
    results = []
    passed_count = 0
    total_checks = len(selected_checks)
    if 'json' in selected_checks:
        results.append(valid)
        if valid:
            passed_count += 1
    for check_name, check_func in check_entries:
        if check_name in selected_checks:
            result = check_func()
            results.append(result)
            if result:
                passed_count += 1
    if all(results):
        print('üéâ All selected validations PASSED!')
    else:
        print('‚ö†Ô∏è Some selected validations FAILED.')
    print(f'üìà Validation Summary: {passed_count}/{total_checks} checks passed.')

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Validate OSWorld task delivery')
    parser.add_argument('delivery_folder', help='Path to the Deliverable folder')
    parser.add_argument('task_id', help='The task ID')
    parser.add_argument('--checks', default='all', help='Comma-separated list of checks to run (default: all)')
    parser.add_argument('--rearrange', action='store_true', help='Move misplaced files into the expected directory layout before validation')
    parser.add_argument('--phase', type=int, choices=[1, 2], default=1, help='Phase of validation (1 for pass@16, 2 for pass@8)')
    args = parser.parse_args()
    if args.checks == 'all':
        selected_checks = ['json', 'passk', 'structure', 'sft_score', 'annotator_scores', 'no_args']
        if args.phase == 1:
            selected_checks.append('notebook_assistant')
    else:
        selected_checks = [check.strip() for check in args.checks.split(',')]
        available_checks = ['json', 'passk', 'structure', 'sft_score', 'annotator_scores', 'no_args']
        if args.phase == 1:
            available_checks.append('notebook_assistant')
        invalid_checks = [check for check in selected_checks if check not in available_checks]
        if invalid_checks:
            print(f'‚ùå Invalid checks: {invalid_checks}')
            print(f'‚ÑπÔ∏è Available checks: {available_checks}')
            raise SystemExit(1)
    main(args.delivery_folder, args.task_id, selected_checks, args.rearrange, args.phase)
